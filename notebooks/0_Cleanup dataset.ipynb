{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup dataset\n",
    "Released datasets from the original authors does not comply with `torchvision` dataset convetions. This notebook will help you reformat them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/courses/RANSAC-Flow/notebooks/workspace\n"
     ]
    }
   ],
   "source": [
    "%mkdir workspace\n",
    "%cd workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MegaDepth\n",
    "Please download it from their [Google Drive](https://drive.google.com/file/d/1SikcOvCJ-zznOyCRJCTGtpKtTp01Jx5g/view?usp=sharing) and save it as `MegaDepth.zip`. This includes training (coarse aligned and none-aligned), validation, and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_zip = zipfile.ZipFile('MegaDepth.zip', 'r')\n",
    "dst_zip = zipfile.ZipFile('MegaDepth_cleansed.zip', 'x')\n",
    "\n",
    "src_root_path = zipfile.Path(src_zip, at='MegaDepth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganize training images from `<class>_[123].jpg` to `<class>/[123].jpg`. (Run time 3.5 min.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"train\")\n",
    "\n",
    "src_path = src_root_path / \"MegaDepth_Train\"\n",
    "for file in src_path.iterdir():\n",
    "    cls_name, fname = file.name.split(\"_\", maxsplit=1)\n",
    "    dst_path = root_dir / cls_name / fname\n",
    "\n",
    "    data = file.read_bytes()\n",
    "    dst_zip.writestr(str(dst_path), data, compress_type=zipfile.ZIP_DEFLATED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move validation set. (Run time 1 min.)\n",
    "- `images` (renamed from `img`) contains all images of any given set, class name here does *not* relate to training set.\n",
    "- `matches.csv` (renamed from `corr.csv`) contains all correspondences and matching image paths.\n",
    "- `affine.pkl` (renamed from `coarse.pkl`) contains affine transformation matrix for given image paths in `corr.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"validate\")\n",
    "\n",
    "# move single files\n",
    "src_path = src_root_path / \"Val\"\n",
    "for file in src_path.iterdir():\n",
    "    # we deal with images later\n",
    "    if file.is_dir():\n",
    "        continue\n",
    "\n",
    "    rename = {\"corr.csv\": \"matches.csv\", \"coarse.pkl\": \"affine.pkl\"}\n",
    "    dst_path = root_dir / rename[file.name]\n",
    "\n",
    "    data = file.read_bytes()\n",
    "    dst_zip.writestr(str(dst_path), data, compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "# move images, these already comply with torchvision format\n",
    "src_path = src_root_path / 'Val'/\"img\"\n",
    "for cls_name in src_path.iterdir():\n",
    "    for file in cls_name.iterdir():\n",
    "        # NOTE these *.name are actually zipfile.Path, not pathlib.Path\n",
    "        dst_path = root_dir / \"images\" / str(int(cls_name.name)) / file.name\n",
    "\n",
    "        data = file.read_bytes()\n",
    "        dst_zip.writestr(str(dst_path), data, compress_type=zipfile.ZIP_DEFLATED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move testing set. (Run time 1.5 min.)\n",
    "- `images` (renamed from `test1600Pairs`) contains all images of any given set, class name here does *not* relate to training set.\n",
    "- `matches.csv` (renamed from `test1600Pairs.csv`) contains all correspondences and matching image paths. Update `scene` column to save class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"test\")\n",
    "\n",
    "# move single files\n",
    "src_path = src_root_path / \"Test\"\n",
    "for file in src_path.iterdir():\n",
    "    # we deal with images later\n",
    "    if file.is_dir():\n",
    "        continue\n",
    "\n",
    "    rename = {\"test1600Pairs.csv\": \"matches.csv\"}\n",
    "    dst_path = root_dir / rename[file.name]\n",
    "\n",
    "    # extract to DataFrame\n",
    "    data = file.read_bytes()\n",
    "    buffer = io.BytesIO(data)\n",
    "    df = pd.read_csv(buffer)\n",
    "\n",
    "    df_src = df[\"source_image\"].str.split(pat=\"_\", n=1, expand=True)\n",
    "    df_src.columns = [\"scene\", \"source_image\"]\n",
    "    df_dst = df[\"target_image\"].str.split(pat=\"_\", n=1, expand=True)\n",
    "    df_dst.columns = [\"scene\", \"target_image\"]\n",
    "\n",
    "    mask = df_src[\"scene\"] != df_dst[\"scene\"]\n",
    "    if mask.any():\n",
    "        raise RuntimeError(\"found source-target image pairs from different scenes\")\n",
    "\n",
    "    # we want to consolidate scenes (class names)\n",
    "    df[[\"scene\", \"source_image\"]] = df_src\n",
    "    df[\"target_image\"] = df_dst[\"target_image\"]\n",
    "\n",
    "    # turn to numeric to remove leading zeros\n",
    "    df[\"scene\"] = df[\"scene\"].astype(int)\n",
    "\n",
    "    # restore from DataFrame\n",
    "    buffer = io.BytesIO()\n",
    "    df.to_csv(buffer, index=False)\n",
    "    buffer.seek(0)\n",
    "    data = buffer.read()\n",
    "\n",
    "    dst_zip.writestr(str(dst_path), data, compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "src_path = src_root_path / \"Test\" / \"test1600Pairs\"\n",
    "for file in src_path.iterdir():\n",
    "    cls_name, fname = file.name.split(\"_\", maxsplit=1)\n",
    "    dst_path = root_dir / \"images\" / str(int(cls_name)) / fname\n",
    "\n",
    "    data = file.read_bytes()\n",
    "    dst_zip.writestr(str(dst_path), data, compress_type=zipfile.ZIP_DEFLATED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you execute this cell to save the final zip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_zip.close()\n",
    "dst_zip.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab9a4cd533c26959fc5e643c878bb3c1316795e5debd5e7351e48820d8136be1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('ransacflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
