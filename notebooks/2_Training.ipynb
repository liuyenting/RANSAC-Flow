{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training fine flow prediction\n",
    "Assuming source image $I_s$ and target image $I_t$ are already coarsely aligned, this notebook will try to predict a fine flow $F_{s\\rightarrow t}$ between them. \n",
    "\n",
    "TODO describe objective functions used in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume you already have a folder called `workspace` that contains zipped dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/courses/RANSAC-Flow/notebooks/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd ../notebooks/workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages that we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "We already pack some datasets used in the original paper as `LightningDataModule`. We will import it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ransacflow.data import MegaDepthDataModule\n",
    "\n",
    "mega_depth = MegaDepthDataModule(\"MegaDepth_cleansed.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add some sanity check for the dataset here, previews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO setup environments for the following training sessions, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME is it possible to share the Trainer object across all 3 stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1\n",
    "Only train the **reconstruction loss**. \n",
    "\n",
    "It is based on the idea that source image $I_s$ warped with the predicted flow $F_{s\\rightarrow t}$ should align well with the target image $I_t$. In the original work, they use the structural similarity (SSIM) as the perception model. \n",
    "$$ L_{\\text{recon}}\\left(I_s, I_t\\right) = \\sum_{(x,y)\\in I_t} M_t^{\\text{cycle}}(x,y) \\left( 1 - \\text{SSIM}\\left\\lbrace I_s(x^\\prime, y^\\prime), I_t(x,y) \\right\\rbrace \\right) $$\n",
    "\n",
    "FIXME wtf is M_t doing here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "file integrity is not explicitly tested\n",
      "file integrity is not explicitly tested\n",
      "\n",
      "  | Name              | Type                  | Params\n",
      "------------------------------------------------------------\n",
      "0 | feature_extractor | FeatureExtractor      | 2.8 M \n",
      "1 | correlator        | NeighborCorrelator    | 0     \n",
      "2 | flow              | FlowPredictor         | 1.8 M \n",
      "3 | matchability      | MatchabilityPredictor | 1.7 M \n",
      "------------------------------------------------------------\n",
      "6.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.2 M     Total params\n",
      "24.948    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11769c1796964ad096d8822542abe427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.conda/envs/ransacflow/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "validation.__getitem__\n",
      "validation.__getitem__\n",
      "validation.__getitem__\n",
      "/home/andy/.conda/envs/ransacflow/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:116: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992f43bf1074462da7d70c1d4bc6f90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/.conda/envs/ransacflow/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:145: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\n",
      "/home/andy/.conda/envs/ransacflow/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "# DEBUG move dataset here for easy debug\n",
    "from ransacflow.data import MegaDepthDataModule\n",
    "\n",
    "image_size = 224\n",
    "mega_depth = MegaDepthDataModule(\"MegaDepth_cleansed.zip\", size=image_size)\n",
    "# DEBUG end\n",
    "\n",
    "from ransacflow.train import RANSACFlowModelStage1\n",
    "\n",
    "ransac_flow = RANSACFlowModelStage1(\n",
    "    alpha=0, beta=0, gamma=0, image_size=image_size, kernel_size=7, lr=2e-4\n",
    ")\n",
    "\n",
    "# FIXME unify TB logging location and experiment name\n",
    "trainer = Trainer(\n",
    "    max_epochs=200,\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"RANSAC-Flow\"),\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=3)],\n",
    ")\n",
    "trainer.fit(ransac_flow, mega_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All following command line interface are copied from the original implementation, temporarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    --nEpochs 200 \n",
    "    --lr 2e-4\n",
    "    --kernelSize 7 \n",
    "--imgSize 224 \n",
    "--batchSize 16 \n",
    "    --lambda-match 0.0, alpha \n",
    "    --mu-cycle 0.0, beta \n",
    "    --grad 0.0, gamma  \n",
    "    --trainMode flow \n",
    "--margin 88 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2\n",
    "Train jointly the **reconstruction loss** and **cycle consistency of the flow**.\n",
    "\n",
    "Asides from the reconstruction loss mentioned in previous stage, we start to enforce cycle consistency of the flow by\n",
    "$$ L_{\\text{cycle}} = \\sum_{(x,y) \\in I_t} M_t^{\\text{circle}} (x,y) \\left\\lVert \\left(x^\\prime, y^\\prime \\right), \\bm{F}_{t\\rightarrow s}(x,y) \\right\\rVert_2 $$\n",
    "\n",
    "FIXME what happened with (x^\\prime, y^\\prime), F_{t->s}? Are they multiplied?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ransacflow.train import RANSACFlowModelStage2\n",
    "\n",
    "ransac_flow = RANSACFlowModelStage2(alpha=0, beta=1, gamma=0, kernel_size=7, lr=2e-4)\n",
    "\n",
    "# FIXME unify TB logging location and experiment name\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"RANSAC-Flow_stage2\"),\n",
    "    callbacks=[EarlyStoppping(monitor=\"val_loss\", min_delta=0.01, patience=3)],\n",
    ")\n",
    "trainer.fit(ransac_flow, MegaDepthDataModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    --nEpochs 50 \n",
    "    --lr 2e-4 \n",
    "    --kernelSize 7 \n",
    "--imgSize 224 \n",
    "--batchSize 16 \n",
    "    --lambda-match 0.0, alpha\n",
    "    --mu-cycle 1.0, beta\n",
    "    --grad 0.0, gamma\n",
    "    --trainMode flow \n",
    "--margin 88 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3\n",
    "Train all three losses together: **reconstruction loss**, **cycle consistency of the flow**, and **matchability loss**.\n",
    "\n",
    "Matchability mask can be seen as pixel-wise weights for the reconstruction and cycle consistency loss. These losses encourage th matchability to be zero. To counteract this effect, the matchability loss encourages the matchability mask to be close to one.\n",
    "\n",
    "FIXME equation for matchability\n",
    "FIXME still doesn't understand what matchability actually implies, what is the difference between this and cycle loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ransacflow.train import RANSACFlowModelStage3\n",
    "\n",
    "ransac_flow = RANSACFlowModelStage3(alpha=0.01, beta=1, gamma=0, kernel_size=7, lr=2e-4)\n",
    "\n",
    "# FIXME unify TB logging location and experiment name\n",
    "trainer = Trainer(\n",
    "    max_epochs=50,\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"RANSAC-Flow_stage3\"),\n",
    "    callbacks=[EarlyStoppping(monitor=\"val_loss\", min_delta=0.01, patience=3)],\n",
    ")\n",
    "trainer.fit(ransac_flow, MegaDepthDataModule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    --nEpochs 50 \n",
    "    --lr 2e-4\n",
    "    --kernelSize 7 \n",
    "--imgSize 224 \n",
    "--batchSize 16 \n",
    "    --lambda-match 0.01, alpha\n",
    "    --mu-cycle 1.0, beta\n",
    "    --grad 0.0, gamma\n",
    "    --trainMode flow+match \n",
    "--margin 88 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4.1\n",
    "This additional stage fine tune on SOMETHING MAGICAL, so the output image introduce less distortions.\n",
    "\n",
    "TODO need to update description from the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4.2\n",
    "This additional stage uses perceptual loss, \n",
    "\n",
    "TODO add description about why and how to use perceptual loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
